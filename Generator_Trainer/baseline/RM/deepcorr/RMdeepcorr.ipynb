{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926c4003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nixilin/anaconda3/envs/deepcorr/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Random Mutation:generates evasive packet sequences by randomly varying inter-packet interval time within a packet\n",
    "sequence iteratively. This method is not a baseless weak attack but is recognized in prior works.\n",
    "\n",
    "'''\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pathlib\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = []\n",
    "\n",
    "all_runs={'8872':'192.168.122.117','8802':'192.168.122.117','8873':'192.168.122.67','8803':'192.168.122.67',\n",
    "         '8874':'192.168.122.113','8804':'192.168.122.113','8875':'192.168.122.120',\n",
    "        '8876':'192.168.122.30','8877':'192.168.122.208','8878':'192.168.122.58'}\n",
    "\n",
    "for name in all_runs:\n",
    "    dataset += pickle.load(open('../../target_model/deepcorr/dataset/%s_tordata300.pickle' % name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533c652c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance of the RM dataset: 2357.104\n",
      "L2 distance of the adv: 327.621\n",
      "L2 rate 0.139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "flow_size = 300\n",
    "row = [0,3]\n",
    "l2s_test = torch.zeros(len(dataset),1, 8, flow_size)\n",
    "for index in range(len(dataset)):\n",
    "    l2s_test[index, 0, 0,:] = torch.tensor(dataset[index]['here'][0]['<-'][:flow_size]) * 1000.0  \n",
    "    l2s_test[index, 0, 1,:] = torch.tensor(dataset[index]['there'][0]['->'][:flow_size]) * 1000.0  \n",
    "    l2s_test[index, 0, 2,:] = torch.tensor(dataset[index]['there'][0]['<-'][:flow_size]) * 1000.0  \n",
    "    l2s_test[index, 0, 3,:] = torch.tensor(dataset[index]['here'][0]['->'][:flow_size]) * 1000.0  \n",
    "\n",
    "    l2s_test[index, 0, 4,:] = torch.tensor(dataset[index]['here'][1]['<-'][:flow_size]) / 1000.0  \n",
    "    l2s_test[index, 0, 5,:] = torch.tensor(dataset[index]['there'][1]['->'][:flow_size]) / 1000.0  \n",
    "    l2s_test[index, 0, 6,:] = torch.tensor(dataset[index]['there'][1]['<-'][:flow_size]) / 1000.0  \n",
    "    l2s_test[index, 0, 7,:] = torch.tensor(dataset[index]['here'][1]['->'][:flow_size]) / 1000.0  \n",
    "def RM(data,device):\n",
    "    row = [0,3]\n",
    "    adv = torch.randn(data[:, 0, row, :].shape).to(device)\n",
    "    adv= torch.mul(adv, data[:, 0, row, :])*0.25\n",
    "    adv=torch.clamp(adv,0*adv,1*data[:,0,row,:])\n",
    "    adv_data = data[:,0,row,:] + adv\n",
    "    data[:,0,row,:] = adv_data\n",
    "    return data,adv\n",
    "data,adv=RM(l2s_test,'cpu')\n",
    "print('L2 distance of the RM dataset: %.3f' % torch.linalg.norm( data[:,0,row,:], ord=2,dim=(-1)).mean())\n",
    "print('L2 distance of the adv: %.3f' % torch.linalg.norm(adv, ord=2,dim=(-1)).mean())\n",
    "print('L2 rate %.3f' % (torch.linalg.norm(adv, ord=2,dim=(-1)).mean() / torch.linalg.norm(data[:,0,row,:], ord=2,dim=(-1)).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ce73d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3\n"
     ]
    }
   ],
   "source": [
    "negetive_samples = 199\n",
    "#使用随机扰动的方式来生成数据，取扰动大小为(0,data[0][0][0][:flow_size].mean()),为了保证一致性，也只扰动客户端的时间数据a\n",
    "\n",
    "def generate_data(dataset,test_index, flow_size):\n",
    "    global negetive_samples\n",
    "\n",
    "    #测试集样本填充(all_samples*(negetive_samples+1),1,8,flow_size)\n",
    "    index = 0\n",
    "    random_test = [] + test_index\n",
    "    l2s_test = torch.zeros((len(test_index) * (negetive_samples + 1),1, 8, flow_size)) \n",
    "    labels_test = torch.zeros((len(test_index) * (negetive_samples + 1))) \n",
    "\n",
    "    for i in test_index:\n",
    "        if index % (negetive_samples + 1) != 0:\n",
    "            print(index, len(random_test))\n",
    "            raise ValueError(\"Index is not a multiple of (negetive_samples + 1)\")\n",
    "        m = 0\n",
    "\n",
    "        np.random.shuffle(random_test)\n",
    "        for idx in random_test:\n",
    "            if idx == i or m > (negetive_samples - 1):\n",
    "                continue\n",
    "            \n",
    "            #第三维是0，则是时间\n",
    "            m += 1\n",
    "            l2s_test[index, 0, 0,:] = torch.tensor(dataset[idx]['here'][0]['<-'][:flow_size]) * 1000.0  \n",
    "            l2s_test[index, 0, 1,:] = torch.tensor(dataset[i]['there'][0]['->'][:flow_size]) * 1000.0  \n",
    "            l2s_test[index, 0, 2,:] = torch.tensor(dataset[i]['there'][0]['<-'][:flow_size]) * 1000.0  \n",
    "            l2s_test[index, 0, 3,:] = torch.tensor(dataset[idx]['here'][0]['->'][:flow_size]) * 1000.0  \n",
    "\n",
    "            l2s_test[index, 0, 4,:] = torch.tensor(dataset[idx]['here'][1]['<-'][:flow_size]) / 1000.0  \n",
    "            l2s_test[index, 0, 5,:] = torch.tensor(dataset[i]['there'][1]['->'][:flow_size]) / 1000.0  \n",
    "            l2s_test[index, 0, 6,:] = torch.tensor(dataset[i]['there'][1]['<-'][:flow_size]) / 1000.0  \n",
    "            l2s_test[index, 0, 7,:] = torch.tensor(dataset[idx]['here'][1]['->'][:flow_size]) / 1000.0  \n",
    "            labels_test[index] = 0\n",
    "            index += 1\n",
    "\n",
    "        l2s_test[index, 0, 0,:] = torch.tensor(dataset[i]['here'][0]['<-'][:flow_size]) * 1000.0  \n",
    "        l2s_test[index, 0, 1,:] = torch.tensor(dataset[i]['there'][0]['->'][:flow_size]) * 1000.0  \n",
    "        l2s_test[index, 0, 2,:] = torch.tensor(dataset[i]['there'][0]['<-'][:flow_size]) * 1000.0  \n",
    "        l2s_test[index, 0, 3,:] = torch.tensor(dataset[i]['here'][0]['->'][:flow_size]) * 1000.0  \n",
    "\n",
    "        l2s_test[index, 0, 4,:] = torch.tensor(dataset[i]['here'][1]['<-'][:flow_size]) / 1000.0  \n",
    "        l2s_test[index, 0, 5,:] = torch.tensor(dataset[i]['there'][1]['->'][:flow_size]) / 1000.0  \n",
    "        l2s_test[index, 0, 6,:] = torch.tensor(dataset[i]['there'][1]['<-'][:flow_size]) / 1000.0  \n",
    "        l2s_test[index, 0, 7,:] = torch.tensor(dataset[i]['here'][1]['->'][:flow_size]) / 1000.0  \n",
    "        labels_test[index] = 1\n",
    "\n",
    "        index += 1\n",
    "    return l2s_test, labels_test\n",
    "\n",
    "flow_size = 300\n",
    "\n",
    "batch_size = 256\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2000, (2,20), stride=2)\n",
    "        self.max_pool1 = nn.MaxPool2d((1,5), stride=1)\n",
    "        self.conv2 = nn.Conv2d(2000, 800, (4,10), stride=2)\n",
    "        self.max_pool2 = nn.MaxPool2d((1,3), stride=1)\n",
    "        self.fc1 = nn.Linear(49600, 3000)\n",
    "        self.fc2 = nn.Linear(3000, 800)\n",
    "        self.fc3 = nn.Linear(800, 100)\n",
    "        self.fc4 = nn.Linear(100, 1)\n",
    "#         self.d = nn.Dropout2d()\n",
    "    \n",
    "    def weight_init(self):\n",
    "        for m in self._modules:\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.normal_(0.0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "    def forward(self, inp, dropout):\n",
    "        x = inp\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool2(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=dropout)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=dropout)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, p=dropout)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:3\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "print (device)\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "LOADED=torch.load('../../target_model/deepcorr/deepcorr300/tor_199_epoch23_acc0.82dict.pth',map_location=device)\n",
    "model.load_state_dict(LOADED)\n",
    "\n",
    "test_index = pickle.load(open('../../target_model/deepcorr/deepcorr300/test_index300.pickle','rb'))[:1000]\n",
    "\n",
    "# 1. 收集所有模型的预测概率和真实标签\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "result_fpath = pathlib.Path(\"./RMtest_index300_result.p\")\n",
    "test_l2s, test_labels = generate_data(dataset, test_index,  flow_size)\n",
    "test_dataset = TensorDataset(test_l2s.float(), test_labels.float())\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "934e5853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd2a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [02:52<00:00,  4.51it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "\n",
    "row = [0,3]  \n",
    "result_fpath = pathlib.Path(\"./RMtest_index300_result.p\")\n",
    "if result_fpath.exists():\n",
    "    with open(result_fpath, \"rb\") as fp:\n",
    "        all_outputs,all_labels = pickle.load(fp)\n",
    "else:\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for data, labels in tqdm.tqdm(test_loader):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            #data: [batch_size, 1, 8, flow_size]\n",
    "            # 得到模型经过RM扰动的输出\n",
    "            RMdata,adv = RM(data,device)\n",
    "            # print('L2 distance of the RM dataset: %.3f' % torch.linalg.norm( data[:,0,row,:], ord=2,dim=(-1)).mean())\n",
    "            # print('L2 distance of the adv: %.3f' % torch.linalg.norm(adv, ord=2,dim=(-1)).mean())\n",
    "            # print('L2 rate %.3f' % (torch.linalg.norm(adv, ord=2,dim=(-1)).mean() / torch.linalg.norm(data[:,0,row,:], ord=2,dim=(-1)).mean()))\n",
    "            \n",
    "            outputs_raw = model(RMdata, dropout=0.0)\n",
    "\n",
    "            # 使用 sigmoid 转换为概率\n",
    "            outputs_prob = torch.sigmoid(outputs_raw).cpu().numpy()\n",
    "            \n",
    "            # 收集概率和标签\n",
    "            all_outputs.extend(outputs_prob.flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "    # 转换为numpy数组\n",
    "    all_outputs = np.array(all_outputs)\n",
    "    all_labels = np.array(all_labels)\n",
    "    with open(result_fpath, \"wb\") as fp:\n",
    "        pickle.dump((all_outputs,all_labels), fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepcorr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
